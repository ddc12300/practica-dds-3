---
title: "Supervised Learning - practica 3"
author: "Raquel Abad y Daniel Díaz"
date: "06/01/2024"
output: html_document
---
## Exploración de datos
####1. Exploración de los datos de tráfico de red disponibles

Para realizar esta práctica disponemos de una muestra de tráfico de red en un fichero csv. Si importamos el fichero csv como un dataframe con la función dim() podemos ver que disponemos de 10000 muestras de tráfico de red con 49 categorias cada una.
Las categorias de las muestras son: srcip, sport, dstip, dsport, proto, state, dur, sbytes, dbytes, sttl, dttl, sloss, dloss, service, Sload, Dloa, Sjit, Djit, Stime, Ltime, Sintpkt, Dintpkt, tcprtt, synack, ackdat, is_sm_ips_ports, ct_state_ttl, ct_flw_http_mthd, is_ftp_login, ct_ftp_cmd, ct_srv_src, ct_srv_dst, ct_dst_ltm, ct_src_ltm, ct_src_dport_ltm, ct_dst_sport_ltm, ct_dst_src_ltm, attack_cat, Label.


La categoría srcip es de tipo character.
La categoría sport es de tipo numeric.
La categoría dstip es de tipo character.
La categoría dsport es de tipo numeric.
La categoría proto es de tipo character.
La categoría state es de tipo character.
La categoría dur es de tipo numeric.
La categoría sbytes es de tipo numeric.
La categoría dbytes es de tipo numeric.
La categoría sttl es de tipo numeric.
La categoría dttl es de tipo numeric.
La categoría sloss es de tipo numeric.
La categoría dloss es de tipo numeric.
La categoría service es de tipo character.
La categoría Sload es de tipo numeric.
La categoría Dload es de tipo numeric.
La categoría Sjit es de tipo numeric.
La categoría Djit es de tipo numeric.
La categoría Stime es de tipo numeric.
La categoría Ltime es de tipo numeric.
La categoría Sintpkt es de tipo numeric.
La categoría Dintpkt es de tipo numeric.
La categoría tcprtt es de tipo numeric.
La categoría synack es de tipo numeric.
La categoría ackdat es de tipo numeric.
La categoría is_sm_ips_ports es de tipo numeric.
La categoría ct_state_ttl es de tipo numeric.
La categoría ct_flw_http_mthd es de tipo numeric.
La categoría is_ftp_login es de tipo numeric.
La categoría ct_ftp_cmd es de tipo numeric.
La categoría ct_srv_src es de tipo numeric.
La categoría ct_srv_dst es de tipo numeric.
La categoría ct_dst_ltm es de tipo numeric.
La categoría ct_src_ltm es de tipo numeric.
La categoría ct_src_dport_ltm es de tipo numeric.
La categoría ct_dst_sport_ltm es de tipo numeric.
La categoría ct_dst_src_ltm es de tipo numeric.
La categoría attack_cat es de tipo character.
La categoría Label es de tipo numeric.


## Generación del modelo de ML
####2. Comprender el código utilizado para segmentar el conjunto de datos entre datos de entrenamiento y datos de validación.



```{r setup, include=FALSE, cache=TRUE}
knitr::opts_chunk$set(echo = TRUE)

library("jsonlite", warn.conflicts = FALSE)
library("ggplot2", warn.conflicts = FALSE)
library("lattice", warn.conflicts = FALSE)
library("caret", warn.conflicts = FALSE)
library("gbm", warn.conflicts = FALSE)
library("pROC", warn.conflicts = FALSE)

set.seed(42)
```

# Detección de ataques con aprendizaje supervisado

El siguiente ejercicio consiste en la optmización de un modelo de Machine Learning capaz de detectar ataques a partir de logs de un firewall. Para este propósito, se realizará una prueba de concepto con una pequeña muestra de logs previamente etiquetados como tráfico normal o ataque.

## Load of the data sets

Se proporcionan los siguentes archivos:

-   features.csv
-   events.csv

```{r tidy_data, echo=FALSE}
base_path <- "./"

events <- read.csv(paste(base_path, "events_sample.csv", sep = ""))
features <- read.csv(paste(base_path, "features.csv", sep = ""))
```

### Events analysis/exploration

```{r events_stats, echo=FALSE}


```

### Data enrichment

```{r data_enrich, echo=FALSE}


```

## Feature engineering

```{r feat_eng, echo=FALSE}
# El modelo requiere nombres de columna simples y features numericas o factor
names(events) <- stringr::str_replace_all(names(events), "_", "")
events <- as.data.frame(unclass(events), stringsAsFactors = TRUE)

# Etiquetamos la columna Label con valores categoricos
events$Label <- ifelse(events$Label == 1, "ATTACK", "NORMAL")
events$Label <- as.factor(events$Label)
events$attackcat <- NULL

outcomeName <- 'Label'
predictorsNames <- names(events)[names(events) != outcomeName]

prop.table(table(events$Label))
```

## Build model

### Create train and test data sets

Hemos modificado la proporción de datos utilizados para el entrenamiento y la validación, pasando de una división previa a una división donde el 80% de los datos se utilizan para entrenamiento y el 20% para validación. Este ajuste busca optimizar la cantidad de datos disponibles para el aprendizaje del modelo, mejorando potencialmente su rendimiento.

```{r train_test, echo=FALSE}
splitIndex <- createDataPartition(events[,outcomeName], p = .80, list = FALSE, times = 1)

trainDF <- events[ splitIndex,]
testDF  <- events[-splitIndex,]
```

### Prepare object with training configuration (how we are gonna train the model)

Anteriormente, no estábamos utilizando la validación cruzada en nuestro proceso de entrenamiento y evaluación. Hemos cambiado esta aproximación para incorporar la validación cruzada con 2 pliegues. Este cambio tiene como objetivo proporcionar una evaluación más rigurosa y fiable del modelo, permitiéndonos obtener una estimación más precisa de su capacidad para generalizar a nuevos datos. La validación cruzada funciona dividiendo el conjunto de datos de manera aleatoria en dos partes o "pliegues". En el caso de la validación cruzada con 2 pliegues, el conjunto de datos se divide en dos partes iguales: una parte se utiliza para entrenar el modelo y la otra parte se utiliza para evaluarlo. Luego, este proceso se repite, pero esta vez, la parte que se había utilizado para la evaluación se usa para el entrenamiento y viceversa. Esto asegura que todo el conjunto de datos se utilice tanto para el entrenamiento como para la evaluación, proporcionando una visión completa del rendimiento del modelo. Al utilizar la validación cruzada, mitigamos el riesgo de sobreajuste, que ocurre cuando un modelo aprende patrones específicos de los datos de entrenamiento tan bien que falla al intentar predecir resultados en datos no vistos. 

```{r model_config, echo=FALSE}
# Configuración de trainControl para usar validación cruzada
objControl <- trainControl(method = "cv",  # Usar validación cruzada
                           number = 2,    # Número de pliegues (folds) para la validación cruzada
                           classProbs = TRUE, # Calcular probabilidades de clase (necesario para AUC)
                           summaryFunction = twoClassSummary, # Resumen para clasificación binaria
                           savePredictions = "final", # Opcional: guardar predicciones para análisis posterior
                           verboseIter = FALSE) 
```

### Train the model

```{r model_train, echo=FALSE}
objModel <- train(trainDF[,predictorsNames], trainDF[,outcomeName], 
                  method = 'gbm', 
                  trControl = objControl,  
                  metric = "ROC",
                  preProc = c("center", "scale"))
# summary(objModel)
```

### Test model

```{r model_test, echo=FALSE}
predictions <- predict(object = objModel, testDF[, predictorsNames], type = 'raw')
#head(predictions)
```

## Evaluate model

```{r model_eval, echo=FALSE}
print(postResample(pred = predictions, obs = as.factor(testDF[,outcomeName])))
```

```{r predic_prob}
# probabilites 
predictions <- predict(object = objModel, testDF[,predictorsNames], type = 'prob')
auc <- roc(ifelse(testDF[,outcomeName] == "ATTACK",1,0), predictions[[2]])
print(auc$auc)
```

```{r var_importance}
plot(varImp(objModel, scale = F))
```

## Conclusiones

La implementación de la validación cruzada y el ajuste en la proporción de datos para entrenamiento y validación han marcado un hito importante en el desarrollo de nuestro proyecto. Al introducir la validación cruzada con 2 pliegues, hemos adoptado un enfoque más riguroso para la evaluación de nuestro modelo, lo que nos ha permitido obtener una visión más precisa y confiable de su capacidad para generalizar a nuevos datos.

El ajuste en la proporción de datos, utilizando el 80% para el entrenamiento y el 20% para la validación, ha optimizado el uso de nuestro conjunto de datos. Este cambio ha permitido que el modelo se beneficie de una mayor cantidad de información durante la fase de aprendizaje, lo cual es crucial para mejorar su capacidad predictiva.

El impacto de estos cambios en el rendimiento del modelo ha sido notable, con un aumento en el AUC de 0.9978 a 0.9996 y, por lo tanto, también mayor precisión, aumentando su valor de 0.9837312 a 0.9904952. Este incremento no solo demuestra la efectividad de las modificaciones realizadas sino que también resalta la calidad y la precisión de nuestro modelo en la detección de ataques a partir de los logs de un firewall.
```
